# -*- coding: utf-8 -*-
"""malicious url detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/154rJRmvj3EvZquCYmpS8Juii_JTPDfpA
"""

# For formatting the datatype and classes in them
import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE


# for extracting the lexcial features from the url
from urllib.parse import urlparse
# this module is required to import tldextract
!pip install tldextract
import tldextract


# for visualization
from IPython.display import display
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt




# required for pre-processing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# required for pre-processing
!pip install category_encoders
import category_encoders as ce


#for validation of all the classification models
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

#For saving all the models and necessary functions
import joblib

# Machine learning models which are required
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import SGDClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier

from google.colab import drive

#Mount Google Drive to load all the datasets from the drive
drive.mount('/content/drive')

# Loading the data of each class
dataset_benign = pd.read_csv("/content/drive/MyDrive/training_dataset.csv")
dataset_benign=dataset_benign[dataset_benign['result']==0]
dataset_benign.rename(columns={'result': 'target'}, inplace=True)
dataset_benign=dataset_benign.drop(['Unnamed: 0','label'],axis=1)

dataset_XSS = pd.read_csv("/content/drive/MyDrive/XSS_urls.csv")

dataset_malware = pd.read_csv("/content/drive/MyDrive/malware_urls.csv")

dataset_phishing = pd.read_csv("/content/drive/MyDrive/phishing_urls.csv")

dataset_spam = pd.read_csv("/content/drive/MyDrive/spam_urls.csv")

#dataset of each class
dataset_benign

dataset_phishing.head()

dataset_malware.head()

dataset_spam.head()

dataset_XSS.head()

#since each of the different classes of malacious urls are saved in different dataset
# So we check the count of each of the dataset
print('The number of rows in Benign dataset is :',dataset_benign.shape[0])
print()
print('----'*20)
print()
print('The number of rows in phishing dataset is :',dataset_phishing.shape[0])
print()
print('----'*20)
print()
print('The number of rows in malware dataset is :',dataset_malware.shape[0])
print()
print('----'*20)
print()
print('The number of rows in  spam dataset is :',dataset_spam.shape[0])
print()
print('----'*20)
print()
print('The number of rows in XSS dataset is :',dataset_XSS.shape[0])

# Now making the final dataset by combining all the datasets with different classes into one dataset

# Concatenate the DataFrames into one
dataset = pd.concat([dataset_benign, dataset_phishing, dataset_malware,dataset_spam,dataset_XSS], ignore_index=True)

# Now, combined_df contains all the rows from benign, phishing, malware , spam and XSS with columns "URL" and "Target".
dataset

# Check how many classes are their for the dataset
dataset['target'].unique()

# Displaying the count of each of these unique target classes
label_counts=dataset['target'].value_counts()
label_counts

# Define a dictionary to map integer values to string names
category_mapping = {0: 'benign', 1: 'phishing', 2: 'malware', 3: 'spam', 4: 'XSS'}

# Create a new DataFrame with the modified "Category" column
new_df = dataset.copy()  # Create a copy of the original DataFrame
new_df['target'] = new_df['target'].replace(category_mapping)

label_countss=new_df['target'].value_counts()
plt.figure(figsize=(6, 6))  # Adjust the figure size as needed
plt.pie(label_countss, labels=label_countss.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Label Types')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle

# Show the pie chart
plt.show()

#Pre Processing step

#checking for null values and also the dtypes of all the columns
dataset.info()

#input format of the dataset before pre-processing
dataset.head()

def extract_features(row):
    # Extract domain info using tldextract
    domain_info = tldextract.extract(row['url'])

    # Calculate scheme length
    scheme_len = len(urlparse(row['url']).scheme)

    # Calculate lengths of different URL components
    url_len = len(row['url'])
    path_len = len(urlparse(row['url']).path)
    param_len = len(urlparse(row['url']).params)
    query_len = len(urlparse(row['url']).query)
    frag_len = len(urlparse(row['url']).fragment)

    # Count specific symbols in the URL
    symbols = ['-', '@', '?', '%', '.']
    count_info = {}
    for sym in symbols:
        count_info['count' + sym] = row['url'].count(sym)

    # Count digits and alphabetic characters in the URL
    count_info['count_digit'] = sum(i.isdigit() for i in row['url'])
    count_info['count_alpha'] = sum(i.isalpha() for i in row['url'])

    # Combine all extracted features
    features = [domain_info.subdomain, domain_info.domain, domain_info.suffix,
                scheme_len, url_len, path_len, param_len, query_len, frag_len,
                count_info['count-'], count_info['count@'], count_info['count?'],
                count_info['count%'], count_info['count.'], count_info['count_digit'],
                count_info['count_alpha']]

    return features

def extract_url(data):
    # Apply the extract_features function to each row and expand the result into separate columns
    data[['subdomain', 'domain', 'suffix',
          'scheme_len', 'url_len', 'path_len', 'param_len', 'query_len', 'frag_len',
          'count-', 'count@', 'count?', 'count%', 'count.', 'count_digit', 'count_alpha']] = data.apply(extract_features, axis=1, result_type='expand')

    return data

DataSet=extract_url(dataset)

DataSet

DataSet.info()

grouped_data = DataSet.groupby('target')['domain'].nunique().reset_index()
grouped_data

import seaborn as sns
sns.barplot(data=grouped_data, x="target", y="domain")
plt.ylabel("Unique domains")
plt.show()

grouped_data1 = DataSet.groupby('target')['subdomain'].nunique().reset_index()
print(grouped_data1)
sns.barplot(data=grouped_data1, x="target", y="subdomain")

grouped_data2 = DataSet.groupby('target')['suffix'].nunique().reset_index()
print(grouped_data2)
sns.barplot(data=grouped_data2, x="target", y="suffix")

# Handling categorical features
count_encoder = ce.CountEncoder(handle_unknown=0)
DataSet_copy=DataSet.copy()
DataSet_copy.iloc[:, 2:6] = count_encoder.fit_transform(DataSet_copy.iloc[:, 2:6])

correlation_matrix=DataSet_copy.corr()
sns.heatmap(correlation_matrix)

"""**Data Transformation**"""

# encoding of categorical features
count_encoder = ce.CountEncoder(handle_unknown=0)
DataSet.iloc[:, 2:5] = count_encoder.fit_transform(DataSet.iloc[:, 2:5])

DataSet.head()

#Saving the encoder in the drive to use it in another file by importing it.
#file_path1 = '/content/drive/My Drive/Model/my_encoder.pkl'
#joblib.dump(count_encoder, file_path1)

# Scaling of  whole dataset
cols = DataSet.columns
scaler_x = StandardScaler()

DataSet.iloc[:, 2:] = pd.DataFrame(scaler_x.fit_transform(DataSet.iloc[:, 2:]), columns=cols[2:])

DataSet.head()

#Saving the scaler in the drive to use it in another file by importing it.
#file_path2 = '/content/drive/My Drive/Model/my_scaler.pkl'
#joblib.dump(scaler_x, file_path2)

#data_to_save = DataSet

# Define the path on Google Drive where you want to save the data
#save_path = 'content/drive/My Drive/Model/DataSet1.csv'  # Change 'Your_Folder' to your desired folder

# Save the data to the specified path
#DataSet.to_csv(save_path, index=False)

"""**Main algorithm**"""

# Sepearing dependent and independent varible
X = DataSet.drop(columns=['target','url'], inplace=False)
Y = DataSet.loc[:, 'target']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=14)

#checking for accuracies of all the classification models using our dataset.

#logistic Regression


from sklearn.metrics import accuracy_score
lr = LogisticRegression(max_iter=10000)
lr.fit(X_train, Y_train)
lr_y_pred = lr.predict(X_test)

print('Accuracy of the Logistic Regression is -->',accuracy_score(Y_test,lr_y_pred))

# Decision Tree

dt = DecisionTreeClassifier(random_state=14)
dt.fit(X_train, Y_train)
dt_y_pred = dt.predict(X_test)
print('Accuracy of the Decision Tree is -->',accuracy_score(Y_test,dt_y_pred))

#Naive Bayes

nb = GaussianNB()
nb.fit(X_train, Y_train)
nb_y_pred = nb.predict(X_test)
print('Accuracy of the Naive Bayes is -->',accuracy_score(Y_test,nb_y_pred))

#Stochastic Gradient descent


sgd = SGDClassifier(n_jobs=-1)
sgd.fit(X_train, Y_train)
sgd_y_pred = sgd.predict(X_test)
print('Accuracy of the Stochastic Gradient descent is -->',accuracy_score(Y_test,sgd_y_pred))

#Random Forest
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=320, verbose=1, n_jobs=-1, random_state=14)
rfc.fit(X_train, Y_train)
rfc_y_pred = rfc.predict(X_test)
print("Confusion Matrix: \n", confusion_matrix(Y_test,rfc_y_pred))

print('---'*20)
class_report = classification_report(Y_test, rfc_y_pred)

print('Classification report :')
print(class_report)


# Extract individual F1 scores for each class
f1_scores = f1_score(Y_test, rfc_y_pred, average=None)

print('---'*20)
print('Classification report  for each individual class:')
for i, f1 in enumerate(f1_scores):
    print(f"F1 Score for Class {i}: {f1}")


print('---'*20)
from sklearn.metrics import accuracy_score


print('Accuracy of the Random Forest is -->',accuracy_score(Y_test,rfc_y_pred))

#XG Boost
import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier
xgboost = xgb.XGBClassifier(objective="multi:softmax", num_class=5,random_state=14)
xgboost.fit(X_train, Y_train)
xgb_y_pred = xgboost.predict(X_test)
print("Confusion Matrix: \n", confusion_matrix(Y_test,xgb_y_pred))

print('---'*20)
class_report = classification_report(Y_test, xgb_y_pred)

print('Classification report :')
print(class_report)


# Extract individual F1 scores for each class
f1_scores = f1_score(Y_test, xgb_y_pred, average=None)

print('---'*20)
print('Classification report  for each individual class:')
for i, f1 in enumerate(f1_scores):
    print(f"F1 Score for Class {i}: {f1}")


print('---'*20)
print('Accuracy of the XGBoost is -->',accuracy_score(Y_test,xgb_y_pred))

# Create a VotingClassifier with soft voting
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from xgboost import XGBClassifier
voting_classifier = VotingClassifier(estimators=[('RandomForest',rfc),('XGboost',xgboost)],voting='soft')
voting_classifier.fit(X_train, Y_train)

voting_classifier.predict(X_test)

voting_y_pred = voting_classifier.predict(X_test)
print("Confusion Matrix: \n", confusion_matrix(Y_test,voting_y_pred))

print('---'*20)
class_report = classification_report(Y_test, voting_y_pred)

print('Classification report :')
print(class_report)


# Extract individual F1 scores for each class
f1_scores = f1_score(Y_test, voting_y_pred, average=None)

print('---'*20)
print('Classification report  for each individual class:')
for i, f1 in enumerate(f1_scores):
    print(f"F1 Score for Class {i}: {f1}")


print('---'*20)
print('Accuracy of the ensemble is -->',accuracy_score(Y_test,voting_y_pred))

# Random Forest
# Split the data into training and testing sets
#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=73)


# Create a Random Forest classifier with 350 trees, SMOTE, and balanced class weights
#model = RandomForestClassifier(n_estimators=300, random_state=73,criterion='entropy',max_depth=30 ,class_weight='balanced',max_features = 0.5)

# Train the model on the resampled training data
#model.fit(X_train, y_train)

# Make predictions on the training data
#y_train_pred = model.predict(X_train)

# Calculate training accuracy
#train_accuracy = accuracy_score(y_train, y_train_pred)

# Generate the training classification report
#train_report = classification_report(y_train, y_train_pred)

# Make predictions on the test data
#y_test_pred = model.predict(X_test)

# Calculate testing accuracy
#test_accuracy = accuracy_score(y_test, y_test_pred)

# Generate the testing classification report
#test_report = classification_report(y_test, y_test_pred)

# Print the training and testing accuracy and classification reports
#print("Training Accuracy:", train_accuracy)
#print("Training Classification Report:")
#print(train_report)

#print("Testing Accuracy:", test_accuracy)
#print("Testing Classification Report:")
#print(test_report)

# XGboost
# Split the dataset into training and testing sets
#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=77)

# Create an XGBoost classifier with 'multi:softprob' objective

##xgb_classifier = XGBClassifier(objective='multi:softprob', num_class=5,random_state=77,n_estimators=700,learning_rate=0.35 ,max_depth=7,min_child_weight =1,class_weight='balanced')

# Train the model
#xgb_classifier.fit(X_train, y_train)

# Get predicted probabilities for each class
#y_pred_prob = xgb_classifier.predict_proba(X_test)

# Convert probabilities to class predictions
#y_test_pred = np.argmax(y_pred_prob, axis=1)

# Make predictions on the training data
#y_train_pred = model.predict(X_train)

# Calculate training accuracy
#train_accuracy = accuracy_score(y_train, y_train_pred)

# Generate the training classification report
#train_report = classification_report(y_train, y_train_pred)


# Calculate testing accuracy
#test_accuracy = accuracy_score(y_test, y_test_pred)

# Generate the testing classification report
#test_report = classification_report(y_test, y_test_pred)

# Print the training and testing accuracy and classification reports
##print("Training Accuracy:", train_accuracy)
#print("Training Classification Report:")
#print(train_report)

#print("Testing Accuracy:", test_accuracy)
#print("Testing Classification Report:")
#print("Testing Accuracy:", test_accuracy)
#print("Testing Classification Report:")
#print(test_report)



#Save the model to a file
#Define the file path on your Google Drive
#file_path3 = '/content/drive/My Drive/Model/my_ensemble.pkl'
#joblib.dump(ensemble_classifier, file_path3)

from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Assuming you have X_train, X_test, y_train, y_test defined


X_train, X_test, y_train, y_test= train_test_split(X, Y, test_size=0.2, random_state=77)

# Base Model 1: Random Forest
rf_model = RandomForestClassifier(
    n_estimators=300,
    random_state=73,
    criterion='entropy',
    max_depth=30,
    class_weight='balanced',
    max_features=0.5
)

rf_model.fit(X, Y)


# Base Model 2: XGBoost
xgb_model = XGBClassifier(
    objective='multi:softprob',
    num_class=5,
    random_state=77,
    n_estimators=700,
    learning_rate=0.35,
    max_depth=7,
    min_child_weight=1,
    class_weight='balanced'
)

xgb_model.fit(X,Y)

# Create a VotingClassifier with soft voting
voting_classifier = VotingClassifier(
    estimators=[
        ('RandomForest', rf_model),
        ('XGBoost', xgb_model)
    ],
    voting='soft'
)

voting_classifier_final = voting_classifier.fit(X,Y)

file_path3 = '/content/drive/My Drive/Model/my_ensemble.pkl'
joblib.dump(voting_classifier_final , file_path3)

# Make predictions using the ensemble classifier
y_pred_final = voting_classifier.predict(X_test)

print("Confusion Matrix: \n", confusion_matrix(y_test, y_pred))

print('---'*20)
class_report = classification_report(y_test, y_pred)

print('Classification report :')
print(class_report)


# Extract individual F1 scores for each class
f1_scores = f1_score(y_test, y_pred, average=None)

print('---'*20)
print('Classification report  for each individual class:')
for i, f1 in enumerate(f1_scores):
    print(f"F1 Score for Class {i}: {f1}")


print('---'*20)

print('Accuracy of the Ensemble is -->',accuracy_score(y_test,y_pred))